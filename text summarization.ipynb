{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Security\n",
      "requirements of GKA protocols have been classified into\n",
      "key privacy requirements, prevention of impersonation attack\n",
      "requirements, key confirmation requirements, key contributive-\n",
      "ness requirements, and perfect forward secrecy requirements\n",
      "[1]. A protocol is said to have perfect forward secrecy\n",
      "if compromise of long-term keys does not compromise past\n",
      "session keys [3]. A protocol provides partial\n",
      "forward secrecy if compromise of long-term keys of one or\n",
      "more specific principals does not compromise the session\n",
      "keys established in previous protocol runs involving those\n",
      "principals [4]. In this paper we view perfect\n",
      "forward secrecy as a special case of partial forward secrecy,\n",
      "where all long-term keys can be compromised, without com-\n",
      "promising the session key. It has been shown that the\n",
      "minimum number of rounds needed for a group key agreement\n",
      "protocol is one, and that protocols based on DH cannot meet\n",
      "this bound [7]. Boyd Nieto (BN) protocol was designed to\n",
      "meet this bound, however failed to provide partial forward\n",
      "secrecy, as compromise of a single long-term secret results in\n",
      "the compromise of the session key [7]. Under strong corruptions, even in\n",
      "the case of DH protocols perfect forward secrecy is assured\n",
      "only if the short-term keys are explicitly erased. Therefore\n",
      "while considering partial forward secrecy we assume strong\n",
      "corruption and hence do not differentiate between long-term\n",
      "and short-term keys and refer to them as secrets used in\n",
      "computation of session key. Degree of partial forward secrecy of a protocol is\n",
      "defined as the highest probability of obtaining the session key,\n",
      "given that secrets used to compute the session key are probably\n",
      "compromised. We illustrate our proposal by comparing BN protocol, A-\n",
      "GDH.2 protocol and ID - Based One Round Authenticated\n",
      "Group key Agreement Protocol with Bilinear Pairing (IDBP)\n",
      "[9]. The number\n",
      "of long-term keys that can be compromised without com-\n",
      "promising the session key is all keys, one key and no key\n",
      "respectively for A-GDH.2 protocol, IDBP protocol and BN\n",
      "protocol.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HRISHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HRISHI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import bs4 as bs\n",
    "import re\n",
    "\n",
    "scraped_data = open(\"original.txt\")\n",
    "article = scraped_data.read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text\n",
    "# Removing Square Brackets and Extra Spaces\n",
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "# Removing special characters and digits\n",
    "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "formatted_article_text = re.sub(r'\\s+',' ', formatted_article_text)\n",
    "sentence_list = nltk.sent_tokenize(article_text)\n",
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "words = word_tokenize(article)\n",
    "\n",
    "# Creating a frequency table to keep the\n",
    "# score of each word\n",
    "\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "\tword = word.lower()\n",
    "\tif word in stopWords:\n",
    "\t\tcontinue\n",
    "\tif word in freqTable:\n",
    "\t\tfreqTable[word] += 1\n",
    "\telse:\n",
    "\t\tfreqTable[word] = 1\n",
    "\n",
    "# Creating a dictionary to keep the score\n",
    "# of each sentence\n",
    "sentences = sent_tokenize(article)\n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in sentences:\n",
    "\tfor word, freq in freqTable.items():\n",
    "\t\tif word in sentence.lower():\n",
    "\t\t\tif sentence in sentenceValue:\n",
    "\t\t\t\tsentenceValue[sentence] += freq\n",
    "\t\t\telse:\n",
    "\t\t\t\tsentenceValue[sentence] = freq\n",
    "\n",
    "\n",
    "\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "\tsumValues += sentenceValue[sentence]\n",
    "\n",
    "# Average value of a sentence from the original text\n",
    "\n",
    "average = int(sumValues / len(sentenceValue))\n",
    "\n",
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "\tif (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "\t\tsummary += \" \" + sentence\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
